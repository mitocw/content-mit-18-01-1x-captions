#
# File:   content-mit-18-01-1x-captions/U3S3 Convergence rate of Newton's method [98jvsVf6PYA].txt
#
# Captions for MITx 18.01.1x module
#
# This file has 108 caption lines.
#
# Do not add or delete any lines.  If there is text missing at the end, please add it to the last line.
#
#----------------------------------------

Why does Newton's method work?
We're going to explore the rate of convergence
of Newton's method.
And to do this, I'm going to start with function f.
And I'll let x star denote the root
that we want to approximate using Newton's method.
That means that f of x star is equal to 0,
because that's what it means to be a root of the function f.
When we start to apply Newton's method,
I start by making a guess x0.
And this guess has some inherent error in it.
The error is the distance between the root x
star and my guess x0.
I'm going to call this error epsilon sub 0, because epsilon
is the Greek letter that mathematicians like
to use to denote small numbers.
So epsilon sub 0 is equal to x star minus x sub 0.
We're interested in understanding how quickly
Newton's method converges.
And to understand that, we're going
to try to understand the order of magnitude
of consecutive error terms.
So the next error term, we're going to call epsilon sub 1.
This is going to be equal to x star minus x1,
where x1 is found applying Newton's method.
So x1 is equal to x sub 0 minus f of x0
divided by f prime of x0.

What we're going to discover is that epsilon 1
is on the order of magnitude of epsilon 0 squared.

Of course, there are a lot of details hiding inside
of big O notation.
And we need to look at these details.
So once we work them out, we'll be
able to see what can go wrong with this method,
as well as why it converges so quickly when it does work.
The main trick that we're going to use in exploring the details
is a linear approximation of the function f at the point x0.
So remember that the linear approximation for the function
f at x0 is given by the equation f of x is equal to f of x0 plus
f prime of x0 times the quantity x minus x0
plus big O of the quantity x minus x0 squared.

Next, I'm going to set x equal to x star.

We already said that f of x star is equal to 0.
And this term, x star minus x0 is what we called epsilon 0.
That's the error term of our first guess.
So this gives us an equation 0 is equal to f of x0 plus
f prime of x0 times epsilon 0 plus big O of epsilon 0
squared.
I'm going to go ahead and solve this to write f of x0
in terms of f prime of x0 and the error term.
And this gives me f of x0 is equal to negative
f prime of x0 times epsilon 0 plus big O of epsilon 0
squared.
Note the change in sign on this big O term.
You probably expected me to write negative big O
of epsilon 0 squared.
But this is one of the rules of big O.
Remember, the only thing that matters
is the order of magnitude.
So negative big O of epsilon 0 squared
is the same thing as positive big O of epsilon 0 squared.
And we typically use pluses rather than minuses
whenever possible.
Now, let's get back to analyze this error term epsilon 1
and see what we get.
We define epsilon 1 as x star minus x1.
I'm going to write x1 in terms of x0
using the formula from Newton's method.
So this gives me that epsilon 1 is
equal to x star minus x sub 0 plus f
of x0 divided by f prime of x0.
And this is where I'm going to go ahead and just
plug in this formula for f of x0 that I found here.
This was the main trick, and this
is where we're applying it.
So plugging this in, I get that epsilon sub 1
is equal to epsilon 0 plus 1 over f prime of x0 times
the quantity negative f prime of x0 times epsilon 0
plus big O of epsilon 0 squared.
This epsilon 0 is going to cancel with this term right
here.
And I'm left with 1 over f prime of x0 times big O of epsilon 0
squared, which of course is on the order of epsilon 0 squared.

What's the upshot of this?
Well, the argument that we just made
didn't depend on this 0 or this 1.
I can replace 0 with n and 1 with n plus 1,
and I'm going to get the exact same relationship
between consecutive error terms.
So this means that the error term epsilon sub n plus 1
is on the order of epsilon n squared,
which is on the order of the error epsilon sub n minus 1
to the fourth, et cetera.
As long as this derivative on the bottom
doesn't get too small-- because if this gets too small,
this error term is going to get big-- the error
terms converge to 0 quite quickly.
And this approximation will work very fast.
Of course, this method doesn't always work out that well.
So we'll explore the ways that this method
fails in the next video.
